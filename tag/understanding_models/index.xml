<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>understanding_models | Home</title>
    <link>/tag/understanding_models/</link>
      <atom:link href="/tag/understanding_models/index.xml" rel="self" type="application/rss+xml" />
    <description>understanding_models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 12 Jan 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>understanding_models</title>
      <link>/tag/understanding_models/</link>
    </image>
    
    <item>
      <title>Transformers are Multi-State RNNs</title>
      <link>/publication/tova/</link>
      <pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate>
      <guid>/publication/tova/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Morphosyntactic Probing of Multilingual BERT Models</title>
      <link>/publication/morphosyntactic_probing/</link>
      <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
      <guid>/publication/morphosyntactic_probing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers</title>
      <link>/publication/how_much_does_attention/</link>
      <pubDate>Thu, 06 Oct 2022 00:00:00 +0000</pubDate>
      <guid>/publication/how_much_does_attention/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ABC: Attention with Bounded-memory Control</title>
      <link>/publication/abc/</link>
      <pubDate>Mon, 11 Oct 2021 00:00:00 +0000</pubDate>
      <guid>/publication/abc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effects of Parameter Norm Growth During Transformer Training: Inductive Bias from Gradient Descent</title>
      <link>/publication/norm_growth/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      <guid>/publication/norm_growth/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Provable Limitations of Acquiring Meaning from Ungrounded Form: What will Future Language Models Understand?</title>
      <link>/publication/gpt300/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/publication/gpt300/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Random Feature Attention</title>
      <link>/publication/rfa/</link>
      <pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/publication/rfa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Formal Hierarchy of RNN Architectures</title>
      <link>/publication/rnn_hierarchy/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/publication/rnn_hierarchy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PaLM: A Hybrid Parser and Language Model</title>
      <link>/publication/palm/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/publication/palm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RNN Architecture Learning with Sparse Regularization </title>
      <link>/publication/sparsifying/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/publication/sparsifying/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rational Recurrences</title>
      <link>/publication/rr/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/publication/rr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines</title>
      <link>/publication/sopa/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>/publication/sopa/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
